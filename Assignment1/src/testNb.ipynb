{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from torchvision.io import read_image\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhrishi23\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class animalFaceDataset(Dataset):\n",
    "    def __init__(self, dataPath) -> None:\n",
    "        self.dataPath = dataPath\n",
    "\n",
    "        catPath = Path(os.path.join(self.dataPath,'cat'))\n",
    "        dogPath = Path(os.path.join(self.dataPath,'dog'))\n",
    "        wildPath = Path(os.path.join(self.dataPath,'wild'))\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        PathsToTraverse = [catPath,dogPath,wildPath]\n",
    "\n",
    "        for labelIndex in range(3):\n",
    "            for eachImg in PathsToTraverse[labelIndex].iterdir():\n",
    "                self.images.append(eachImg)\n",
    "                self.labels.append(labelIndex)\n",
    "\n",
    "        self.transforms = T.Compose([T.Resize((128,128)),T.ToTensor()])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        originalImg = default_loader(self.images[index])\n",
    "        resized_img = self.transforms(originalImg)\n",
    "        return resized_img\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataPath = r\"D:\\MTech_IISc\\OneDrive - Indian Institute of Science\\Third Semester\\ADRL\\Assignment1\\Dataset\\train\"\n",
    "train_dataset = animalFaceDataset(traindataPath)\n",
    "\n",
    "evaldataPath = r\"D:\\MTech_IISc\\OneDrive - Indian Institute of Science\\Third Semester\\ADRL\\Assignment1\\Dataset\\val\"\n",
    "eval_dataset = animalFaceDataset(evaldataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batchSize = 16\n",
    "latent_dim = 150\n",
    "cnn_hidden_channels = [32, 64, 128, 256, 512,1024]\n",
    "reversedChannels = cnn_hidden_channels.copy()\n",
    "reversedChannels.reverse()\n",
    "learning_rate = 0.001\n",
    "number_of_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batchSize, shuffle=True)\n",
    "eval_loader =  DataLoader(dataset=eval_dataset, batch_size= batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim, cnn_hidden_channels) -> None:\n",
    "        super(Encoder,self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cnn_hidden_channels = cnn_hidden_channels\n",
    "\n",
    "        modules = []\n",
    "        in_channels = 3 \n",
    "\n",
    "        for h_dim in self.cnn_hidden_channels:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                                kernel_size= 3, stride= 2, padding  = 1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.allCNNLayers = nn.Sequential(*modules)\n",
    "\n",
    "        self.fcForMu = nn.Linear(self.cnn_hidden_channels[-1]*4, latent_dim)\n",
    "        self.fcForVar = nn.Linear(self.cnn_hidden_channels[-1]*4, latent_dim)\n",
    "\n",
    "    def forward(self,sample):\n",
    "        #sample : [bs,Channels, Height, Width]\n",
    "\n",
    "        sample = self.allCNNLayers(sample)\n",
    "        #sample : [bs, 1024, 2, 2]\n",
    "\n",
    "        sample = torch.flatten(sample,start_dim=1)\n",
    "        #sample : [bs, 1024*4]\n",
    "\n",
    "        mu = self.fcForMu(sample)\n",
    "        logvar = self.fcForVar(sample)\n",
    "\n",
    "        return mu,logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleLatentVars(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(SampleLatentVars,self).__init__()\n",
    "    \n",
    "    def forward(self, mu, logvar):\n",
    "        #mu : [bs, latent_dim], logvar : [bs, latent_dim]\n",
    "\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        stdGauss = torch.rand_like(std)\n",
    "        #stdGauss : [bs, latent_dim]\n",
    "\n",
    "        sampledZs = stdGauss*std + mu\n",
    "        #samplesZs : [bs, latent_dim]\n",
    "\n",
    "        return sampledZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, cnn_hidden_channels) -> None:\n",
    "        super(Decoder,self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cnn_hidden_channels = cnn_hidden_channels #[1024,512,256,128,64,32]\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        self.InputToConvTranspose = nn.Linear(latent_dim, cnn_hidden_channels[0] * 4)\n",
    "\n",
    "        for i in range(len(cnn_hidden_channels) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(cnn_hidden_channels[i],\n",
    "                                       cnn_hidden_channels[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride = 2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(cnn_hidden_channels[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "        self.deconvolve = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(cnn_hidden_channels[-1],\n",
    "                                               cnn_hidden_channels[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1),\n",
    "                            nn.BatchNorm2d(cnn_hidden_channels[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv2d(cnn_hidden_channels[-1], out_channels= 3,\n",
    "                                      kernel_size= 3, padding= 1),\n",
    "                            nn.Tanh())\n",
    "        \n",
    "    def forward(self, sampledZs):\n",
    "        #sampledZs : [bs, latent_dim]\n",
    "\n",
    "        inputToDeconvolve = self.InputToConvTranspose(sampledZs).view(-1,1024,2,2)\n",
    "        #inputToDeconvolve : [bs, 1024, 2, 2]\n",
    "\n",
    "        deconvolved = self.deconvolve(inputToDeconvolve)\n",
    "        #deconvolved : [bs, 32, 64,64]\n",
    "\n",
    "        img = self.final_layer(deconvolved)\n",
    "        #img : [bs, 3, 128,128]\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vaeModel(nn.Module):\n",
    "    def __init__(self, encoder, sampler, decoder) -> None:\n",
    "        super(vaeModel,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.sampler = sampler\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, sample):\n",
    "        #sample : [bs, channels, H, W]\n",
    "\n",
    "        mu, logvar = self.encoder(sample)\n",
    "        #mu : [bs, latent_dim]\n",
    "        #logVar : [bs,latent_dim]\n",
    "        \n",
    "        sampledZs = self.sampler(mu,logvar)\n",
    "        #sampledZs : [bs, latent_dim]\n",
    "\n",
    "        reconstructed = self.decoder(sampledZs)\n",
    "        #reconstructed: [bs, 3, H, W]\n",
    "\n",
    "        return reconstructed, mu, logvar # We need to return mu and logvar because it is needed further to calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_dim=latent_dim, cnn_hidden_channels=cnn_hidden_channels)\n",
    "sampler = SampleLatentVars()\n",
    "decoder = Decoder(latent_dim=latent_dim, cnn_hidden_channels=reversedChannels)\n",
    "\n",
    "model = vaeModel(encoder=encoder, sampler=sampler, decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(org_image, reconstructed_image, mu, logvar):\n",
    "    #org_image : [bs, channels, H, W]\n",
    "    #reconstructed_image : [bs, channels, H, W]\n",
    "    #mu : [bs, latent_dim]\n",
    "    #logvar : [bs, logvar]\n",
    "\n",
    "    mse = F.mse_loss(org_image,reconstructed_image)\n",
    "    kld_loss = torch.mean(-0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim = 1), dim = 0)\n",
    "\n",
    "    loss = mse + kld_loss\n",
    "\n",
    "    return loss, mse, kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcValidationLoss(model,valid_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    for eachBatch in valid_loader:\n",
    "        reconstructed,mu,logvar = model(eachBatch)\n",
    "        loss,_,_ = calculate_loss(eachBatch,reconstructed,mu,logvar)\n",
    "        running_loss += loss\n",
    "\n",
    "    avg_loss = running_loss/len(valid_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\MTech_IISc\\OneDrive - Indian Institute of Science\\Third Semester\\ADRL\\Assignment1\\src\\wandb\\run-20231007_112759-zrcioe5l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hrishi23/ADRLAssignment1VAE/runs/zrcioe5l' target=\"_blank\">jumping-haze-2</a></strong> to <a href='https://wandb.ai/hrishi23/ADRLAssignment1VAE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hrishi23/ADRLAssignment1VAE' target=\"_blank\">https://wandb.ai/hrishi23/ADRLAssignment1VAE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hrishi23/ADRLAssignment1VAE/runs/zrcioe5l' target=\"_blank\">https://wandb.ai/hrishi23/ADRLAssignment1VAE/runs/zrcioe5l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss :  tensor(1.4483, grad_fn=<AddBackward0>)\n",
      "Validation loss :  tensor(0.9316, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 8388608 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\MTech_IISc\\OneDrive - Indian Institute of Science\\Third Semester\\ADRL\\Assignment1\\src\\testNb.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m train_metrics \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m\"\u001b[39m:loss,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain_step\u001b[39m\u001b[39m\"\u001b[39m:step,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m wandb\u001b[39m.\u001b[39mlog(train_metrics)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m val_loss \u001b[39m=\u001b[39m calcValidationLoss(model,eval_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m val_metrics \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m:val_loss,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain_step\u001b[39m\u001b[39m\"\u001b[39m:step\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m wandb\u001b[39m.\u001b[39mlog(val_metrics)\n",
      "\u001b[1;32md:\\MTech_IISc\\OneDrive - Indian Institute of Science\\Third Semester\\ADRL\\Assignment1\\src\\testNb.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m eachBatch \u001b[39min\u001b[39;00m valid_loader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     reconstructed,mu,logvar \u001b[39m=\u001b[39m model(eachBatch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     loss,_,_ \u001b[39m=\u001b[39m calculate_loss(eachBatch,reconstructed,mu,logvar)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\MTech_IISc\\OneDrive - Indian Institute of Science\\Third Semester\\ADRL\\Assignment1\\src\\testNb.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m sampledZs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler(mu,logvar)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#sampledZs : [bs, latent_dim]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m reconstructed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(sampledZs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#reconstructed: [bs, 3, H, W]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m reconstructed, mu, logvar\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\MTech_IISc\\OneDrive - Indian Institute of Science\\Third Semester\\ADRL\\Assignment1\\src\\testNb.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m inputToDeconvolve \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mInputToConvTranspose(sampledZs)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1024\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m#inputToDeconvolve : [bs, 1024, 2, 2]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m deconvolved \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeconvolve(inputToDeconvolve)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m#deconvolved : [bs, 32, 64,64]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MTech_IISc/OneDrive%20-%20Indian%20Institute%20of%20Science/Third%20Semester/ADRL/Assignment1/src/testNb.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_layer(deconvolved)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\activation.py:777\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 777\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_slope, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:1632\u001b[0m, in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mleaky_relu_(\u001b[39minput\u001b[39m, negative_slope)\n\u001b[0;32m   1631\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1632\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, negative_slope)\n\u001b[0;32m   1633\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 8388608 bytes."
     ]
    }
   ],
   "source": [
    "#train loop\n",
    "wandb.init(project=\"ADRLAssignment1VAE\",\n",
    "        config={\n",
    "            \"epochs\": number_of_epochs,\n",
    "            \"batch_size\": batchSize,\n",
    "            \"lr\": learning_rate\n",
    "            })\n",
    "\n",
    "config = wandb.config\n",
    "model.train()\n",
    "\n",
    "step = 0\n",
    "for epochs in range(config.epochs):\n",
    "    for eachBatch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed,mu,logvar = model(eachBatch)\n",
    "        loss,_,_ = calculate_loss(eachBatch,reconstructed,mu,logvar)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step%50 == 49:\n",
    "            train_metrics = {\n",
    "                \"train_loss\":loss,\n",
    "                \"train_step\":step,\n",
    "            }\n",
    "            wandb.log(train_metrics)\n",
    "            val_loss = calcValidationLoss(model,eval_loader)\n",
    "            val_metrics = {\n",
    "                \"val_loss\":val_loss,\n",
    "                \"train_step\":step\n",
    "            }\n",
    "            wandb.log(val_metrics)\n",
    "            print(\"train Loss : \",loss)\n",
    "            print(\"Validation loss : \", val_loss)\n",
    "        step += 1\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envForADRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
